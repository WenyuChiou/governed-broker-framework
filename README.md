# Governed Broker Framework

<div align="center">

**A governance middleware for LLM-driven Agent-Based Models**

[![English](https://img.shields.io/badge/lang-English-blue)](README.md#english) [![ä¸­æ–‡](https://img.shields.io/badge/lang-ä¸­æ–‡-red)](README.md#ä¸­æ–‡)

</div>

---

## English

### âœ¨ v0.3 Multi-LLM Extensibility

| v0.2 Skill-Governed | v0.3 Extensible |
|---------------------|-----------------|
| Single LLM adapter | Multi-LLM Provider Registry |
| Hardcoded validators | Dynamic validator loading |
| Sync only | Async + Rate limiting |

ğŸ‘‰ See [`docs/skill_architecture.md`](docs/skill_architecture.md) for architecture details.

### Quick Start

#### Single LLM (Simple)
```bash
pip install -r requirements.txt
cd examples/skill_governed_flood
python run_experiment.py --model llama3.2:3b --num-agents 100 --num-years 10
```

#### Multi-LLM (Advanced)
```python
from providers import OllamaProvider, OpenAIProvider
from interfaces import LLMProviderRegistry

# Register multiple providers
registry = LLMProviderRegistry()
registry.register("local", OllamaProvider(model="llama3.2:3b"))
registry.register("cloud", OpenAIProvider(api_key="..."))

# Use different LLMs for different tasks
local_response = registry.get("local").invoke(prompt)
cloud_response = registry.get("cloud").invoke(prompt)
```

### Key Components

| Component | Purpose |
|-----------|---------|
| `SkillBrokerEngine` | Main orchestrator |
| `LLMProviderRegistry` | Multi-LLM management |
| `DomainConfigLoader` | YAML-driven config |
| `ValidatorFactory` | Dynamic validator loading |
| `RateLimiter` | API rate control |

### Validation Pipeline

1. **Admissibility** - Skill exists? Agent eligible?
2. **Feasibility** - Preconditions met?
3. **Constraints** - Once-only? Annual limit?
4. **Effect Safety** - Safe state changes?
5. **PMT Consistency** - Reasoning consistent?
6. **Uncertainty** - Response confident?

### License

MIT

---


## ä¸­æ–‡

### âœ¨ v0.3 å¤š LLM æ“´å……æ€§

| v0.2 æŠ€èƒ½æ²»ç† | v0.3 å¯æ“´å…… |
|---------------|-------------|
| å–®ä¸€ LLM é©é…å™¨ | Multi-LLM Provider Registry |
| å›ºå®šé©—è­‰å™¨ | å‹•æ…‹é©—è­‰å™¨è¼‰å…¥ |
| åŒæ­¥è™•ç† | éåŒæ­¥ + é€Ÿç‡é™åˆ¶ |

ğŸ‘‰ è©³è¦‹ [`docs/skill_architecture.md`](docs/skill_architecture.md)

### å¿«é€Ÿé–‹å§‹

#### å–®ä¸€ LLMï¼ˆç°¡å–®ï¼‰
```bash
pip install -r requirements.txt
cd examples/skill_governed_flood
python run_experiment.py --model llama3.2:3b --num-agents 100 --num-years 10
```

#### å¤š LLMï¼ˆé€²éšï¼‰
```python
from providers import OllamaProvider, OpenAIProvider
from interfaces import LLMProviderRegistry

# è¨»å†Šå¤šå€‹ LLM æä¾›è€…
registry = LLMProviderRegistry()
registry.register("local", OllamaProvider(model="llama3.2:3b"))
registry.register("cloud", OpenAIProvider(api_key="..."))

# æ ¹æ“šéœ€æ±‚ä½¿ç”¨ä¸åŒ LLM
local_response = registry.get("local").invoke(prompt)
cloud_response = registry.get("cloud").invoke(prompt)
```

### æ ¸å¿ƒå…ƒä»¶

| å…ƒä»¶ | ç”¨é€” |
|------|------|
| `SkillBrokerEngine` | ä¸»å”èª¿å™¨ |
| `LLMProviderRegistry` | å¤š LLM ç®¡ç† |
| `DomainConfigLoader` | YAML é©…å‹•é…ç½® |
| `ValidatorFactory` | å‹•æ…‹é©—è­‰å™¨è¼‰å…¥ |
| `RateLimiter` | API é€Ÿç‡æ§åˆ¶ |

### é©—è­‰ç®¡ç·š

1. **Admissibility** - æŠ€èƒ½å­˜åœ¨ï¼Ÿä»£ç†æœ‰æ¬Šé™ï¼Ÿ
2. **Feasibility** - å‰ç½®æ¢ä»¶æ»¿è¶³ï¼Ÿ
3. **Constraints** - å–®æ¬¡é™åˆ¶ï¼Ÿå¹´åº¦é™åˆ¶ï¼Ÿ
4. **Effect Safety** - ç‹€æ…‹è®Šæ›´å®‰å…¨ï¼Ÿ
5. **PMT Consistency** - æ¨ç†ä¸€è‡´ï¼Ÿ
6. **Uncertainty** - å›æ‡‰ç¢ºå®šï¼Ÿ

### æˆæ¬Š

MIT

