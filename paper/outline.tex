% =============================================================================
% SAGE: A Governance Middleware for LLM-Driven Agent-Based Models
%       of Human–Water Systems
%
% Target: Water Resources Research — Technical Reports: Methods
% Format: AGU (13 PU limit)
% =============================================================================
\documentclass[draft]{agujournal2019}
\usepackage{apacite}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{graphicx}

\journalname{Water Resources Research}

\begin{document}

\title{SAGE: A Governance Middleware for LLM-Driven Agent-Based Models of Human--Water Systems}

\authors{
  Wen-Yu Chen\affil{1},
  Second Author\affil{1}
}
\affiliation{1}{Department of Civil and Environmental Engineering, Lehigh University, Bethlehem, PA, USA}

\correspondingauthor{Wen-Yu Chen}{wec225@lehigh.edu}

% ===========================================================================
% KEY POINTS (3 bullet points, ≤140 characters each)
% ===========================================================================
\begin{keypoints}
\item SAGE eliminates 33\% hallucination rate in ungoverned LLM agents while preserving genuine behavioral diversity
\item Effective Behavioral Entropy (EBE) metric separates true decision diversity from hallucination-inflated entropy
\item Governance middleware transfers across domains: flood adaptation (100 agents, 10 yr) and irrigation (78 agents, 42 yr)
\end{keypoints}

\begin{abstract}
Large language models (LLMs) offer a promising path toward cognitively realistic
agent-based models (ABMs) for water resources planning, but unconstrained LLM
agents produce physically impossible decisions---a phenomenon we term
\emph{behavioral hallucination}. We present SAGE (Structured Agent Governance
Engine), an open-source middleware that enforces domain-specific physical and
institutional constraints on LLM-driven agents while preserving emergent
behavioral diversity. SAGE implements a three-pillar architecture: (1)~a
rule-based validator chain that rejects impossible actions, (2)~a tiered
cognitive memory system that encodes prior experience, and (3)~a priority
context builder that structures LLM prompts with domain knowledge. We introduce
the Effective Behavioral Entropy (EBE) metric, defined as $\text{EBE} = H_{\text{norm}}
\times (1 - R_H)$, which disentangles genuine decision diversity from
hallucination-inflated entropy. In a flood adaptation case study (100 agents,
10~years, 7 LLM configurations), ungoverned agents exhibit a 33\% hallucination
rate; SAGE-governed agents reduce this to $<$2\% while maintaining EBE 32\%
higher. We demonstrate domain transferability through a Colorado River
irrigation case study (78 districts, 42~years). The framework, metrics, and
experiment code are available at [GitHub URL].
\end{abstract}

% Plain Language Summary (required by AGU)
\section*{Plain Language Summary}
Artificial intelligence language models can power virtual agents that make
human-like decisions in water management simulations. However, without
oversight, these agents make impossible choices---like buying flood insurance
they already own or elevating a home that is already raised. We developed SAGE,
a software layer that checks each agent's decision against physical and
institutional rules before it takes effect, while still allowing agents to make
diverse, realistic choices. We show that unchecked agents make impossible
decisions 33\% of the time, inflating the apparent diversity of their behavior.
Our governance middleware eliminates these errors while preserving genuine
decision-making variety. We demonstrate the approach in two water domains:
household flood adaptation and Colorado River irrigation management.

% ===========================================================================
% 1. INTRODUCTION (~800 words, ~1.6 PU)
% ===========================================================================
\section{Introduction}

% Paragraph 1: LLMs in ABMs — promise
% - Generative agents (Park et al., 2023) show human-like behavior
% - Growing interest in LLM-ABMs for environmental/water systems
% - Advantage over utility-maximizing agents: heterogeneous, context-sensitive

% Paragraph 2: The hallucination problem
% - LLMs produce plausible but physically impossible outputs
% - In water ABMs: re-elevate elevated homes, re-insure insured properties
% - Current ABM frameworks lack physical constraint enforcement
% - Shumailov et al. (2024): model collapse from recursive training

% Paragraph 3: Gap and contribution
% - No governance middleware for LLM-driven water ABMs
% - Contribution 1: SAGE architecture (3 pillars)
% - Contribution 2: EBE metric for measuring true diversity
% - Contribution 3: Two-domain validation (flood + irrigation)
% - Open source for community adoption

% ===========================================================================
% 2. SAGE ARCHITECTURE (~1000 words, ~2 PU)
% ===========================================================================
\section{SAGE Architecture}

% 2.1 Three-Pillar Design
\subsection{Three-Pillar Design}
% - Pillar 1: Governance (rule-based validator chain)
%   - YAML-defined rules with conditions and actions
%   - Priority ordering: block > override > warn
%   - Domain-agnostic: same engine for flood and irrigation
%
% - Pillar 2: Cognitive Memory
%   - Window memory (v2): sliding window of recent events
%   - Human-centric memory (v3): arousal-weighted episodic storage
%   - Affect tag injection into prompts
%
% - Pillar 3: Priority Context (TieredContextBuilder)
%   - Tier 1 (must-include): agent state, current conditions
%   - Tier 2 (should-include): memory summaries, neighbor info
%   - Tier 3 (nice-to-have): historical trends, background

% 2.2 Skill Registry and Validator Chain
\subsection{Skill Registry and Validator Chain}
% - Skills: named actions with pre/post conditions
% - SkillBrokerEngine: receives LLM output → parse → validate → execute
% - Retry logic: if rejected, re-prompt with explanation
% - Audit trail: every decision logged with validation status

% 2.3 Domain Instantiation
\subsection{Domain Instantiation}

% Table 1: Domain mapping
\begin{table}[ht]
\caption{SAGE instantiation for two water resource domains.}
\label{tab:domain_mapping}
\centering
\begin{tabular}{lll}
\toprule
Component & Flood Adaptation & Irrigation Management \\
\midrule
Skills & elevate, insure, relocate, & increase, decrease, \\
       & both, do\_nothing & efficiency, acreage, maintain \\
Physical validators & already\_elevated, & water\_right\_cap, \\
                    & already\_insured & already\_efficient \\
Institutional & --- & compact\_allocation, \\
validators & & drought\_severity \\
Memory engine & Flood trauma recall & Regret feedback \\
Appraisal theory & PMT (TP/CP) & Water PMT (WTA/WCA) \\
Agents & 100 households $\times$ 10 yr & 78 districts $\times$ 42 yr \\
\bottomrule
\end{tabular}
\end{table}

% ===========================================================================
% 3. METRICS (~400 words, ~0.8 PU)
% ===========================================================================
\section{Metrics}

% 3.1 Normalised Shannon Entropy
% H = -sum(p_i * log2(p_i))
% H_norm = H / log2(k), k = number of possible actions

% 3.2 Hallucination Rate
We define \emph{behavioral hallucination} as an action $a_t$ proposed by an
LLM agent that violates physical or institutional constraints given the
agent's state $s_{t-1}$ at the previous timestep.  Formally, let
$\mathcal{A}(s_{t-1})$ denote the set of feasible actions given state
$s_{t-1}$.  An action is a behavioral hallucination if $a_t \notin
\mathcal{A}(s_{t-1})$.  This differs from textual hallucination
\citep{ji2023survey} in that the output may be linguistically coherent but
physically impossible---for example, an agent proposing to elevate an
already-elevated home or to adopt irrigation efficiency technology it already
owns.  The hallucination rate is
\begin{equation}
R_H = \frac{n_{\text{hall}}}{n_{\text{total}}}
\label{eq:rh}
\end{equation}
where $n_{\text{hall}}$ counts decisions satisfying $a_t \notin \mathcal{A}(s_{t-1})$
over the evaluation window (years~2--$T$; year~1 is excluded because no prior
state exists).

% 3.3 Effective Behavioral Entropy (EBE)
The Effective Behavioral Entropy (EBE) combines normalized Shannon entropy
\citep{shannon1948mathematical} with the hallucination penalty:
\begin{equation}
\text{EBE} = H_{\text{norm}} \times (1 - R_H) = \frac{H}{\log_2 k} \times \left(1 - \frac{n_{\text{hall}}}{n_{\text{total}}}\right)
\label{eq:ebe}
\end{equation}
where $k$ is the number of available actions and $H = -\sum_{i=1}^{k} p_i
\log_2 p_i$ is the Shannon entropy of the observed action distribution.  EBE
ranges from 0 (no diversity or entirely hallucinated) to 1 (maximum diversity
with zero hallucination).  Unlike raw entropy, EBE penalizes apparent
diversity that arises from physically impossible actions
\citep{jost2006entropy}.

When computing corrected entropy, hallucinated actions are replaced with the
agent's default action (\texttt{DoNothing} for flood, \texttt{maintain\_demand}
for irrigation).  This conservative replacement reflects the counterfactual
that a governed agent would have been blocked and forced to re-decide.  We
acknowledge this choice inflates the default-action count; alternative
approaches such as redistributing hallucination probability across valid
actions would yield different $H_{\text{corr}}$ values.  We report both raw
and corrected entropy to enable comparison (Figure~2).

% ===========================================================================
% 4. CASE STUDY 1: FLOOD ADAPTATION (~800 words, ~1.6 PU)
% ===========================================================================
\section{Case Study 1: Flood Adaptation}

% 4.1 Experimental Design
\subsection{Experimental Design}
% - 100 household agents in flood-prone community
% - 10-year simulation with flood events at years 3, 4, 9
% - Three groups: A (raw LLM), B (SAGE + window memory), C (SAGE + human-centric)
% - Primary model: Gemma 3 4B (also tested: DeepSeek R1 1.5B/8B/14B/32B,
%   Gemma 3 12B/27B — see SI)
% - PMT appraisal: threat/coping constructs from environmental cues

% 4.2 Hallucination Detection
\subsection{Hallucination Detection and Correction}
% - Method: compare decision against prior-year state
% - Hallucination types: re-elevate, re-insure, "both" when already done
% - Group A: 33% hallucination rate (300/900 decisions in years 2-10)
% - Groups B/C: <2% (governance catches and rejects)
% - Figure 2a: Raw vs corrected entropy divergence

% 4.3 Results
\subsection{Results}
% - Figure 2: Two-panel (entropy + relocation)
% - Key finding 1: Group A Raw H_norm = 0.60, EBE = 0.41 (hallucination inflates)
% - Key finding 2: Group C EBE = 0.54, 32% higher than A
% - Key finding 3: Cumulative relocation A=1%, B=33%, C=43%
% - Key finding 4: Year 9 memory persistence — C adds 12 relocations, B adds 1
% - Figure 3: Cross-model scaling shows governance prevents mode collapse

% ===========================================================================
% 5. CASE STUDY 2: COLORADO RIVER IRRIGATION (~600 words, ~1.2 PU)
% ===========================================================================
\section{Case Study 2: Colorado River Irrigation}

% 5.1 Setup
\subsection{Setup}
% - 78 irrigation districts from CRSS database
% - 42-year horizon (2019-2060) with real precipitation projections
% - Hung & Yang (2021) WRR as validation reference
% - Skills: increase_demand, decrease_demand, improve_efficiency,
%   reduce_acreage, maintain_demand
% - Water PMT: WTA (Water Threat Appraisal), WCA (Water Coping Appraisal)

% 5.2 Results
\subsection{Results}
% - Figure 4: Demand trajectories by cluster vs Hung & Yang (2021) Fig 5
% - Governance maintains physically feasible demand trajectories
% - Institutional constraints (compact allocation) prevent over-extraction
% - [Results depend on WP3 production run completion]

% ===========================================================================
% 6. DISCUSSION (~500 words, ~1 PU)
% ===========================================================================
\section{Discussion}

% Paragraph 1: EBE as a diagnostic
% - EBE reveals that ungoverned "diversity" is largely hallucination
% - Implication: raw entropy metrics overestimate LLM-ABM behavioral richness
% - Community should adopt hallucination-corrected metrics

% Paragraph 2: Cross-model robustness
% - Governance prevents mode collapse across 7 model configurations
% - DeepSeek 8B → Elevation lock-in, Gemma 12B → Both lock-in
% - Governed groups maintain H_norm in 0.3-0.8 range

% Paragraph 3: Limitations
% - Single-run results (N=100 provides within-run statistical power)
% - LLM nondeterminism: temperature fixed at default
% - Irrigation case: 78 agents less than ideal for statistical comparison
% - Framework overhead: validator chain adds ~5% latency per decision

% ===========================================================================
% 7. CONCLUSIONS (~300 words, ~0.6 PU)
% ===========================================================================
\section{Conclusions}
% - SAGE: first governance middleware for LLM-driven water ABMs
% - EBE metric: novel contribution for measuring true behavioral diversity
% - Hallucination is structural, not stochastic — governance is essential
% - Two-domain validation demonstrates transferability
% - Open source: GitHub URL for community adoption
% - Future: multi-agent interaction governance, dynamic rule learning

% ===========================================================================
% PU Budget: 1.6 + 2.0 + 0.8 + 1.6 + 1.2 + 1.0 + 0.6 = 8.8 PU (text)
%            + 4 figures + 1 table = ~13 PU total (within limit)
% ===========================================================================

\section*{Data Availability Statement}
Simulation logs, agent configurations, and analysis scripts are archived at
[Zenodo DOI] and available at [GitHub URL] under the MIT License.  The CRSS
precipitation projections are from the U.S.\ Bureau of Reclamation
\citep{usbr2012colorado}.  All raw LLM traces (JSONL format) and governance
audit logs are included in the archive to support independent verification.

\section*{Conflict of Interest}
The authors declare no conflicts of interest relevant to this study.

\section*{Author Contributions}
\textbf{Wen-Yu Chen}: Conceptualization, Methodology, Software, Validation,
Formal analysis, Investigation, Writing -- Original Draft, Visualization.
\textbf{[Second Author]}: Supervision, Writing -- Review \& Editing, Funding
acquisition.

\acknowledgments
This work was supported by [funding source].

\bibliography{references}

\end{document}
